---
title: "AIで作られた広告・画像：表示（ディスクロージャー）と倫理のグローバル基準チェックリスト"
permalink: /ja/ai-ads-ethics/
translations:
  en: /ai-ads-ethics/
  zh: /zh/ai-ads-ethics/
date: 2025-12-19 09:00:00 +0900
categories: ["AI Ethics", "Media Literacy", "Digital Society"]
lang: ja-JP
description: "AI生成・編集の広告や画像をどう見分け、どこで表示が必要になり、何が倫理的に問題になるのか。グローバルな共通基準を平易にまとめた実用チェックリスト。"
image: "/assets/img/post/ethics.png"
og_title: "AI広告・画像：表示と倫理のグローバル基準チェックリスト"
og_description: "法律の講義ではなく、世界共通の実務ルール。誤解を招く点は明示し、権利とプライバシーを守り、拡散前に確認する。"
og_image: "/assets/img/post/ethics.png"
---

AIで作られた画像や広告は、いまやネット上に当たり前に存在します。  
それ自体が問題というより、問題になりやすいのは **「本物の証拠」だと誤認される瞬間** や、**誰かの権利・プライバシー・評判を傷つける** 場合です。

このガイドは「AIは良い／悪い」の議論ではありません。  
多くの国や主要プラットフォームが共有しつつある **透明性（Transparency）＋被害の最小化（Harm Reduction）** という観点から、誰でも使えるチェックポイントをまとめます。

---

## 1) まず整理：AI「生成」とAI「編集」は別物

- **AI生成（Generated）**：画像・動画・音声を“ゼロから”作る  
- **AI編集（Edited）**：元の素材があり、AIで顔・声・背景・意味（文脈）を変える

特に危険なのは、「編集しただけなのに現実の記録のように見える」ケースです。

---

## 2) 世界的に共通する考え方：透明性＋被害の最小化

国ごとに法律は違っても、国際的な枠組みは似た原則を繰り返します。

1) **人を誤認させない（ミスリードしない）**   
2) **避けられる被害を作らない**（プライバシー侵害、名誉毀損、差別、詐欺など）   
3) **説明できる状態にする**（何で、どう作ったかを理解できるように） 

参考（“グローバルの背骨”になる資料）：

- **OECD AI Principles**（透明性・責任ある情報提供）  
  [https://oecd.ai/en/ai-principles](https://oecd.ai/en/ai-principles)
- **UNESCO Recommendation on the Ethics of AI**（人権・説明責任・監査可能性）  
  [https://unesdoc.unesco.org/ark:/48223/pf0000380455](https://unesdoc.unesco.org/ark:/48223/pf0000380455)
- **NIST AI Risk Management Framework**（信頼できるAIの特性）  
  [https://www.nist.gov/itl/ai-risk-management-framework](https://www.nist.gov/itl/ai-risk-management-framework)

---

## 3) 「表示」がほぼ必須になる場面

表示（ディスクロージャー）が重要なのは、コンテンツが **現実として誤解される可能性** が高いとき、または **意思決定** に強く影響するときです。

### 表示を強く・分かりやすくすべき高リスク例
- **実在の人物に見える顔・声**（有名人／一般人／専門家を含む）
- **ニュース映像・現場記録のような見た目**（事件・災害・戦争・デモなど）
- **ビフォー／アフター系の訴求**（健康・美容・ダイエット・施術など）
- **偽の推薦・証言**（「医師が推奨」「有名人が使用」「本人がこう言った」）
- **政治・社会的テーマ**（拡散が信頼を壊しやすい領域）

### 規制とプラットフォームの方向性（“リアルに見えるなら明示”へ）
- EUの透明性方向（Article 50文脈）  
  [https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-50](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-50)
- YouTube：改変・合成コンテンツの開示  
  [https://support.google.com/youtube/answer/14328491](https://support.google.com/youtube/answer/14328491)
- TikTok：AI生成コンテンツのラベル  
  [https://newsroom.tiktok.com/en-us/new-labels-for-disclosing-ai-generated-content](https://newsroom.tiktok.com/en-us/new-labels-for-disclosing-ai-generated-content)
- Meta：AI生成／操作コンテンツのラベル運用  
  [https://about.fb.com/news/2024/04/metas-approach-to-labeling-ai-generated-content-and-manipulated-media/](https://about.fb.com/news/2024/04/metas-approach-to-labeling-ai-generated-content-and-manipulated-media/)

**目安：**  
「え、これ本物？」と思われる余地があるなら、表示は“オプション”ではなく“安全装置”です。

---

## 4) 広告・協賛表示：AI表示とは別に、いつでも重要

画像がAIかどうかに関係なく、**お金・提供・手数料（アフィリエイト）** が絡むなら、受け手が広告だと分かることが重要です。

- 米国 FTC（利害関係＝Material Connection の開示）  
  [https://www.ftc.gov/business-guidance/resources/ftcs-endorsement-guides-what-people-are-asking](https://www.ftc.gov/business-guidance/resources/ftcs-endorsement-guides-what-people-are-asking)
- 英国 ASA/CAP（広告であることの識別）  
  [https://www.asa.org.uk/advice-online/recognising-marketing-communications-overview.html](https://www.asa.org.uk/advice-online/recognising-marketing-communications-overview.html)

**要するに：** “隠す広告”はAI以前に信頼を壊します。

---

## 5) 倫理炎上が起きやすい領域：肖像・プライバシー・著作権

### A) 肖像・声（実在人物）
AIで誰かを「それっぽく」見せて、まるで本人が関わったように見せると、
誤認・名誉・同意（Consent）など複数の問題が重なります。

**実務的な安全線：**  
許可がないなら、実在人物のように見える表現を広告に使わない。

### B) プライバシー
AI画像や動画には、意図せず以下が映り込むことがあります：
- 顔、車のナンバー、住所、所属が分かるID
- 子どもの情報
- 医療・位置情報などの敏感な状況

「特定できる」こと自体がリスクになりえます。

### C) 著作権（“AIが作ったから全部自分のもの”ではない）
著作権の扱いは国によって異なり、まだ整理途中です。入口として：

- 米国 Copyright Office：AI関連ハブ  
  [https://www.copyright.gov/ai/](https://www.copyright.gov/ai/)
- WIPO：AIと知財の全体像  
  [https://www.wipo.int/en/web/frontier-technologies/artificial-intelligence/index](https://www.wipo.int/en/web/frontier-technologies/artificial-intelligence/index)

**安全線：**  
特定ブランドの作風・キャラクター・既存作品に“寄せすぎる”出力は、商用ほど危険度が上がります。

---

## 6) “栄養成分表示”のように出自を残す：Content Credentials（C2PA）

文章での表示に加えて、ファイル自体に「出自（プロビナンス）」を残す動きも強まっています。  
代表的な標準が **C2PA** です。

- C2PA Explainer  
  [https://c2pa.org/specifications/specifications/2.2/explainer/Explainer.html](https://c2pa.org/specifications/specifications/2.2/explainer/Explainer.html)
- C2PA Specifications  
  [https://c2pa.org/specifications/specifications/2.2/index.html](https://c2pa.org/specifications/specifications/2.2/index.html)

完璧な真偽判定ではありませんが、「隠しにくくする」方向に業界が動いているのは確かです。

---

## 7) 30秒チェック（AI広告・画像を見たとき）

1) これ、**現実の証拠**（ニュース映像・記録写真）っぽい？   
2) **実在人物**が出ている（または出ているように見える）？   
3) すぐ買え／寄付しろ／焦れ、など **急がせる**？   
4) 手・歯・文字・反射・照明が不自然に“完璧”すぎない？   
5) **AI生成/編集の表示**はある？   
6) 広告なら **広告/協賛/アフィリエイト表示**はある？   
7) **信頼できる出典リンク**（公式発表、信頼できる報道、研究）はある？   
8) 他の信頼できる情報源でも確認できる？   
9) “100%保証”“衝撃の真実”など **極端な断定**が多すぎない？   
10) 迷ったら **共有を止める**。拡散が被害を増やします。 

---

## 8) 短くて分かりやすい表示文の例

- **AI生成/編集の表示**：  
  「本画像は生成AIで作成、またはAIで編集しています。」
- **現実オイン防止（リアル系）**：  
  「本コンテンツはAI生成（合成）であり、実際の映像・写真ではありません。」
- **広告/アフィリエイト**：  
  「PR（広告）」／「提供」／「アフィリエイトリンクを含みます（購入により手数料を得る場合があります）」

---

### 注意
本記事は一般情報であり、法的助言ではありません。  
ただし日常的な判断としては、世界的に通用しやすい最小基準はこれです：

**誤解される点は明示し、権利とプライバシーを守り、拡散前に確認する。**
