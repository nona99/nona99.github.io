---
title: "AI生成广告与图片：全球披露（标注）与伦理检查清单（大众必读）"
permalink: /zh/ai-ads-ethics/
date: 2025-12-19 09:00:00 +0900
categories: ["AI Ethics", "Media Literacy", "Digital Society"]
lang: zh
description: "用通俗语言解释AI生成/编辑的广告与图片：何时必须标注、哪些做法容易踩伦理红线，以及30秒快速判断清单。"
image: "/assets/img/post/ethics.png"
og_title: "AI广告与图片：全球披露与伦理检查清单"
og_description: "不是法律课，而是全球通用的实用规则：可能误导的地方要说明，保护隐私与权利，转发前先核实。"
og_image: "/assets/img/post/ethics.png"
---


如今，AI生成或AI编辑的图片与广告几乎无处不在。  
这本身不一定是问题。真正容易出事的是：当人们把它 **误当成真实证据**，或者它 **伤害了他人的权利、隐私与名誉**。

这篇文章不讨论“AI好/坏”。它是一份面向大众的全球实用指南，核心只有两点：**透明披露（Transparency）+ 降低伤害（Harm Reduction）**。

---

## 1）先分清两件事：AI“生成”与AI“编辑”不一样

- **AI生成（Generated）**：从零生成图片/视频/音频  
- **AI编辑（Edited）**：有原始素材，但AI改变了内容含义（脸、声音、场景、语境、结论）

风险最高的情况，是成品看起来像“真实记录”（新闻现场、证据、真实推荐）——哪怕它只是“编辑”。

---

## 2）全球共同底线：透明 + 把伤害降到最低

各国法律不同，但国际框架反复强调的原则很像：

1) **不要误导公众**  
2) **不要制造可避免的伤害**（隐私、诽谤、歧视、诈骗等）  
3) **尽量可解释/可追溯**（让人理解“这是什么、怎么来的”）

想了解“全球共识的骨架”，可参考：

- **OECD AI原则**（透明与负责任披露）  
  [https://oecd.ai/en/ai-principles](https://oecd.ai/en/ai-principles)
- **UNESCO《AI伦理建议书》**（人权、问责、可审计性）  
  [https://unesdoc.unesco.org/ark:/48223/pf0000380455](https://unesdoc.unesco.org/ark:/48223/pf0000380455)
- **NIST AI风险管理框架（AI RMF）**（可信AI特性）  
  [https://www.nist.gov/itl/ai-risk-management-framework](https://www.nist.gov/itl/ai-risk-management-framework)

---

## 3）什么时候“必须标注/披露”？（几乎没有商量空间）

披露（标注）最关键的场景，是内容可能被 **当成真实**，或会强烈影响 **购买/捐款/投票/健康选择** 等决策。

### 高风险场景：标注应该醒目、明确
- **逼真的人脸/人声**（像真实人物：名人或普通人都算）
- **像新闻现场的画面**（灾难、冲突、事故、抗议等）
- **“前后对比”效果图**（健康、美容、瘦身、医疗/护理相关）
- **伪造背书/证言**（“医生推荐”“明星在用”“本人说过…”）
- **政治与公共议题**（极易引发信任崩塌与误导传播）

### 监管与平台正在朝同一方向走：越像真实，越要说明
- EU透明度方向（Article 50相关语境）  
  [https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-50](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-50)
- YouTube：对“被修改/合成”的内容要求披露（尤其逼真且影响理解的变更）  
  [https://support.google.com/youtube/answer/14328491](https://support.google.com/youtube/answer/14328491)
- TikTok：AI生成内容标注机制  
  [https://newsroom.tiktok.com/en-us/new-labels-for-disclosing-ai-generated-content](https://newsroom.tiktok.com/en-us/new-labels-for-disclosing-ai-generated-content)
- Meta：对AI生成/被操控媒体的标注做法  
  [https://about.fb.com/news/2024/04/metas-approach-to-labeling-ai-generated-content-and-manipulated-media/](https://about.fb.com/news/2024/04/metas-approach-to-labeling-ai-generated-content-and-manipulated-media/)

**一句话判断：**  
如果正常人会问“这是真的吗？”，披露就不是可选项，而是安全措施。

---

## 4）广告/合作披露：与“AI披露”无关，但同样关键

就算图片完全真实，只要涉及 **付费推广、赞助、赠品、返佣（联盟链接）**，受众就应该能一眼看出这是营销内容。

- 美国 FTC：背书与“利益关联（material connections）”披露常见问答  
  [https://www.ftc.gov/business-guidance/resources/ftcs-endorsement-guides-what-people-are-asking](https://www.ftc.gov/business-guidance/resources/ftcs-endorsement-guides-what-people-are-asking)
- 英国 ASA/CAP：如何识别营销传播（广告必须可识别）  
  [https://www.asa.org.uk/advice-online/recognising-marketing-communications-overview.html](https://www.asa.org.uk/advice-online/recognising-marketing-communications-overview.html)

**大白话：** 涉及钱或好处，就别藏。藏了，比AI本身更伤信任。

---

## 5）最容易引发争议的伦理区：肖像/隐私/版权

### A）肖像与声音：越像真人，风险越大
当AI内容让人以为某人 **参与了** 或 **推荐了** 某产品/观点，就可能触发：
- 误导与欺骗
- 名誉与人格伤害
- 同意（Consent）与权利问题（各地法律不同，但原则相近）

**实用安全线：**  
没有授权，就不要把内容做得像“真人出镜/真人发声”用于广告或强引导场景。

### B）隐私：可识别性本身就是风险
AI图像/视频可能无意暴露：
- 人脸、车牌、地址、单位/学校证件
- 儿童信息
- 医疗/位置等敏感情境

即使你无意伤害，只要“能被识别”，风险就会上升。

### C）版权：不是“AI做的=一定属于我”
全球仍在演进。了解入口：

- 美国版权局：AI与版权专题  
  [https://www.copyright.gov/ai/](https://www.copyright.gov/ai/)
- WIPO：AI与知识产权概览  
  [https://www.wipo.int/en/web/frontier-technologies/artificial-intelligence/index](https://www.wipo.int/en/web/frontier-technologies/artificial-intelligence/index)

**安全线：**  
避免输出过度模仿某个知名品牌风格、角色或具体作品（商用场景尤其敏感）。

---

## 6）“营养标签式”的出处标记：Content Credentials（C2PA）

除了文字披露，行业也在推动把“出处/编辑过程”写进文件元数据，让内容更可追溯。  
代表性标准是 **C2PA**：

- C2PA 解释文档（Explainer）  
  [https://c2pa.org/specifications/specifications/2.2/explainer/Explainer.html](https://c2pa.org/specifications/specifications/2.2/explainer/Explainer.html)
- C2PA 规范索引  
  [https://c2pa.org/specifications/specifications/2.2/index.html](https://c2pa.org/specifications/specifications/2.2/index.html)

这不是完美的“真伪检测器”，但趋势很明确：让大规模隐藏操控变得更难。

---

## 7）30秒快速判断清单（看到AI广告/图片时）

1) 它像不像 **真实证据**（新闻现场、纪录片画面、证明材料）？  
2) 有 **真实人物**（或极像真人）吗？  
3) 它是不是在催你 **立刻买/捐/转发/恐慌**？  
4) 手、牙齿、文字、反射、光影是否“过于完美却又怪怪的”？  
5) 有没有清晰的 **AI生成/编辑披露**？  
6) 如果是广告，是否有 **广告/赞助/联盟链接披露**？  
7) 有没有可信 **来源链接**（官方、权威媒体、研究）？  
8) 其他可靠来源能否印证？还是只有一条爆款帖？  
9) 是否充满极端断言（“100%保证”“震惊真相”“立刻见效”）？  
10) 不确定就先别转发：误导内容最靠“急”和“快”扩散。

---

## 8）简短清晰的披露文案示例（大众一眼能懂）

- **AI生成/编辑披露：**  
  “本图片由生成式AI生成或经AI编辑处理。”
- **防止误认（逼真/像新闻现场时）：**  
  “此内容为AI合成，并非真实拍摄/真实记录。”
- **广告/联盟披露：**  
  “广告/赞助”／“推广合作”／“包含联盟链接（通过链接购买我可能获得佣金）”

---

### 提醒
本文为一般信息，不构成法律意见。  
但日常使用的“全球最低标准”非常简单：

**可能误导的地方要说明；保护隐私与权利；转发/相信之前先核实。**
